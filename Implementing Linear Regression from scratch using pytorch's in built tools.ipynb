{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cede494-d580-4aa9-890c-cd0eb4ae6de7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#the training data can be represented using two matrices, inputs and targets, each with one row per observation, \n",
    "#and one collumn per variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d901354-4f28-4707-92a3-2cfb906e4440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\pc\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8abdc6c-f7fb-4f28-bc10-ccb1299eb490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be79e4b1-0ce4-4ba6-888f-b6c4d2fc044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input(temp,rainfall,humidity representing the respectively as follows)\n",
    "inputs = np.array([[73,67,43],\n",
    "                   [91,88,64],\n",
    "                   [87,134,58],\n",
    "                   [102,43,37],\n",
    "                   [69,96,70]], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "423f2829-bef2-46c1-8463-cc36b500edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets(apples,oranges)\n",
    "targets = np.array([[56,70],\n",
    "                    [81,101],\n",
    "                    \n",
    "                    [119,133],\n",
    "                    [22,37],\n",
    "                    [103,119]], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1e02e4a-e3b5-45c0-94a7-e962ff016a33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "#you then convert inputs and targets from numpy to tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c461370f-59b1-43fe-b2da-9dd7c6c091f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the hypothesis func, we estimate the crop yield. the function is as follows\n",
    "#yield_apple = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "#yield_orangr = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
    "#where b1 and b2 arecontrols error in the model\n",
    "#the above function for both crops can be represented with a matrix of two rows and three columns,\n",
    "#with b1 and b2 being vectors known as the bias.The input values form a matrix and the weghts also form a matrix.\n",
    "#since we do not know the values of the bias and features(wights), \n",
    "#we figure out thei values by tarting with random valiues as follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a985a4d4-68ec-451c-ae31-7b51acd65802",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1554, -0.9765, -0.7454],\n",
      "        [-1.2709,  1.4003,  1.6327]], requires_grad=True)\n",
      "tensor([ 0.3514, -1.7408], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn(2,3, requires_grad=True)\n",
    "b  = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f029ac4-c3e5-4b4a-9a76-06774d95426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model in this case is simply a function that perfoms matrix multiplication between\n",
    "#the inputs and the weghts w (transposed), and then it adds the bias b\n",
    "#we transpose the weights using the .t() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f8bc27b-dd96-46f2-9fef-88cbd21d1ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#we then define the model as follows\n",
    "def model(x):\n",
    "    return x @ w.t() + b\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3893d79d-3bda-4fc3-b362-651886004841",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-108.4757,   69.5067],\n",
      "        [-147.4344,  110.3224],\n",
      "        [-187.2601,  170.0215],\n",
      "        [ -85.0742,  -10.7511],\n",
      "        [-156.2996,  159.2799]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "print(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7087800c-903f-419c-8e64-d2135406dd35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02d67a97-5ac6-45a4-97cf-ddfada2dc243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can see that there is a huge difference between predicted values and actual values.\n",
    "#this is because we just initialized random values as weight and bias\n",
    "#we therfore are going to  use the loss function approach to improve this model by following the procedure belo\n",
    "#-calculate the diference between the predicted and target matrixes\n",
    "#-square all elements of the difference matrix to remove negative values\n",
    "#-calculate  the average of the elements in the resulting matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b89e8b3-f76e-4124-be37-522163c46715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25709.1289, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = preds - targets\n",
    "diff_sqr = diff*diff\n",
    "torch.sum(diff_sqr)/diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07548a3e-2a79-4db7-8e91-fb447526f19f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mse(t1,t2):\n",
    "    diff = t1-t2\n",
    "    return torch.sum(diff*diff)/diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfd510bd-f32c-4ac8-8f44-b9fffe7f1364",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25709.1289, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#the loss tells us how much data the model is losing, the lower the loss, the better the model and vice versa\n",
    "loss = mse(preds,targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c970a12-3d23-40c0-8d6c-d81e2ade2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now we compute the gradient of the loss \n",
    "#the loss is a quadratic function of our wghts and biases, and our objective is to find the set of weghts where the \n",
    "#loss is the lowest on the loss weight graph. A key insight from calculus is that the gradient of the graph of  the loss function indicates\n",
    "#the rate of change of the loss, or the slope of the loss  with respect to our weight and biases\n",
    "#A possitive gradient means that a slight increase in the weight or bias, depending on the graph parameters, will \n",
    "#increase the loss and vice versa.\n",
    "#This is the scenario behind the gradient decent optimization algorithm for model improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d64f725-161b-416f-9003-f6f166e04c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ee5449e-a72e-43ce-8f12-cc14f43841c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1554, -0.9765, -0.7454],\n",
      "        [-1.2709,  1.4003,  1.6327]], requires_grad=True)\n",
      "tensor([[-17650.4258, -20331.5781, -12313.6113],\n",
      "        [   388.3812,   1512.3563,    755.0951]])\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(w.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfe9a898-afc8-4d9e-86a0-2ba3198d3c01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3514, -1.7408], requires_grad=True)\n",
      "tensor([-213.1088,    7.6759])\n"
     ]
    }
   ],
   "source": [
    "print(b)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "943ffb4d-da62-41e2-b55f-e6b92b2147b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before we proceed we reset the gradients to zero by calling .zero_() method on the weights and biases\n",
    "#this is because pytorch accumulates gradients.\n",
    "#that is, the next time we call .backward() method on the loss, the new gradient value will be added to the existing one,\n",
    "#which may lead to unexpected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47454a44-bb69-46f2-8ec6-514d6566ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will now predict the values,although we started with random numbers,\n",
    "#we will improve them to fit our model using gradient decent\n",
    "#we will adjust the weigt and biases using the gradient descent algorithm following the procedure below\n",
    "#-generate predictions\n",
    "#-calculate the loss\n",
    "#-compute gradients\n",
    "#-adjust the weight by subtracting a small quantity proportional to the gradient\n",
    "#-reset the gradient to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46f1124b-1d6c-4df9-ab7c-ffbed7b54b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-we continue with stage 4 since we are done with first three stages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b9da860-8073-4c9d-a652-236f5c873043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#we use torch.no-grad to indicate that pytorch should not track,calculate\n",
    "#or modify gradients with updating the weghts and biases. we then multiply the weight and biase with a very small number since\n",
    "#we do not want to ensure we do not modify the weight by a multiplyying with a large number.we then set weight back to zero\n",
    "with torch.no_grad():\n",
    "    w -= w.grad*1e-5\n",
    "    b -= b.grad*1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f569706-e255-49db-b34e-a83b2dc7ef6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0211, -0.7732, -0.6223],\n",
      "        [-1.2748,  1.3851,  1.6251]], requires_grad=True)\n",
      "tensor([ 0.3536, -1.7409], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#we can see the the values of w and b have increased respectively\n",
    "#therefore we have slightly changed our random values\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57385d3d-55d5-46d7-97fe-6e94a2b600a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17699.6152, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#we now calculate the loss again and compare to the previous loss.with the new w and b, the model should have lower loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds,targets)\n",
    "print(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dadba5-62cf-486b-97a6-21efeb9bfc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to reduce the loss function further, we can repeat the process of adjusting the ewights and biases using the gradient method\n",
    "#each iteration is called epoch,lets train the model for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85c23912-2b7a-4bc0-8391-53c4c4c85c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds,targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae691080-3a2c-4ac4-8cbd-41d372db245b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(354.2454, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#we now calculate the loss again and compare with the previous\n",
    "preds = model(inputs)\n",
    "loss = mse(preds,targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b8ceb5d-77d1-4e92-b0a5-6b465c697f79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n",
      "tensor([[ 63.9169,  64.6069],\n",
      "        [ 82.5962, 101.0249],\n",
      "        [106.9542, 141.3132],\n",
      "        [ 59.5536,   5.9885],\n",
      "        [ 80.2178, 137.5181]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(targets)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d70105-ed68-4b94-a4d6-c40da4a81ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the new obtained values, we can see that the predictios are quite closer than before\n",
    "#we can still further adjust the values for more accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3819a2-0973-4d43-8d9a-2ff654ea74e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8137a8b0-8d55-4394-b2df-6354f2542f97",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m[jovian] Error: Failed to read the Jupyter notebook. Please re-run this cell to try again. If the issue persists, provide the \"filename\" argument to \"jovian.commit\" e.g. \"jovian.commit(filename='my-notebook.ipynb')\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.commit(filenam='linear Regression From Scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9ed69-48aa-4cc7-939a-9ee9de243698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
